{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve Selection Bias using ADAPT library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T10:28:06.395685Z",
     "iopub.status.busy": "2024-03-10T10:28:06.395235Z",
     "iopub.status.idle": "2024-03-10T10:28:15.989479Z",
     "shell.execute_reply": "2024-03-10T10:28:15.988759Z"
    }
   },
   "outputs": [],
   "source": [
    "# set working directory\n",
    "from random import SystemRandom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "# from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# from torch._C import float32\n",
    "import argparse\n",
    "from asyncio.log import logger\n",
    "import os, math\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Importing matplotlib and seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "# import tabulate\n",
    "\n",
    "from adapt.feature_based import DANN, WDGRL\n",
    "from adapt.instance_based import KLIEP, KMM\n",
    "import keras\n",
    "from keras.optimizers.legacy import Adam\n",
    "from keras import Model, Sequential\n",
    "from keras.layers import Dense, Input, Dropout, Conv2D, MaxPooling2D, Flatten, Reshape, GaussianNoise, BatchNormalization\n",
    "\n",
    "import utils\n",
    "from utils import *\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T10:28:15.993351Z",
     "iopub.status.busy": "2024-03-10T10:28:15.992993Z",
     "iopub.status.idle": "2024-03-10T10:28:16.078429Z",
     "shell.execute_reply": "2024-03-10T10:28:16.077937Z"
    }
   },
   "outputs": [],
   "source": [
    "MINI_BATCH = 64\n",
    "EPOCHS = 1000\n",
    "LOAD = None\n",
    "SEED = 42\n",
    "REPEAT = 10\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Set device to GPU\n",
    "    print(\"CUDA is available! Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Set device to CPU\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "param_grid = {\n",
    "            'lambda': [0.05, 0.10],\n",
    "            'hidden':[[50], [100], [100, 100]],\n",
    "            'task':[[50, 1], [100, 1]],\n",
    "            'lr': [0.0001, 0.0005]\n",
    "        }\n",
    "# params = {\n",
    "#             'lambda': 0.05,\n",
    "#             'hidden':[50],\n",
    "#             'task':[50, 50, 1],\n",
    "#             'lr': 0.0001\n",
    "#         }\n",
    "############################################\n",
    "# initilising wandb\n",
    "# wandb.init(project='SeletionBML', entity=\"jmdvinodjmd\")\n",
    "wandb.init(mode=\"disabled\")\n",
    "wandb.run.name = 'SB'\n",
    "makedirs('./results/')\n",
    "experimentID = LOAD\n",
    "if experimentID is None:\n",
    "    experimentID = int(SystemRandom().random()*100000)\n",
    "# checkpoint\n",
    "ckpt_path = os.path.join('./results/checkpoints/KMM_model.ckpt')\n",
    "makedirs('./results/checkpoints/')\n",
    "# set logger\n",
    "log_path = os.path.join(\"./results/logs/\" + \"exp_KMM_\" + str(experimentID) + \".log\")\n",
    "makedirs(\"./results/logs/\")\n",
    "logger = get_logger(logpath=log_path, filepath=\"exp_KMM_\" + str(experimentID) + \".log\", displaying=False)\n",
    "logger.info(\"Experiment \" + str(experimentID))\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T10:28:16.090133Z",
     "iopub.status.busy": "2024-03-10T10:28:16.089828Z",
     "iopub.status.idle": "2024-03-10T10:28:16.111063Z",
     "shell.execute_reply": "2024-03-10T10:28:16.110450Z"
    }
   },
   "outputs": [],
   "source": [
    "def experiment(model_name, data, params, repeat=1):\n",
    "    [X_train, y_train, s_train, X_val, y_val, s_val, X_test, y_test, s_test] = data\n",
    "\n",
    "    # repeating experiment for a given number of times\n",
    "    results_risk = {}\n",
    "    for i in range(repeat):\n",
    "        logger.info('Repeating: ' + str(i+1))\n",
    "        results_risk[i] = {}\n",
    "        #############################\n",
    "        # train\n",
    "        callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, min_delta=0.001)\n",
    "        if model_name == 'KMM':\n",
    "            model = KMM(estimator=get_mlp(params['task'], params['lr']), Xt=X_test, random_state=i, callbacks=callback)\n",
    "        elif model_name == 'KLIEP':\n",
    "            model = KLIEP(estimator=get_mlp(params['task'], params['lr']), Xt=X_test, random_state=i, callbacks=callback)\n",
    "        model.fit(X_train[s_train==0], y_train[s_train==0], validation_data=(X_val[s_val==0], y_val[s_val==0]), epochs=EPOCHS, verbose=1)\n",
    "        # evaluate model\n",
    "        predictions = model.predict(X_val[s_val==0])\n",
    "        results, _ = print_metrics_binary_classification(y_val[s_val==0], predictions, model_name, verbose=1, logger=logger, wandb=wandb)\n",
    "        logger.info(model_name +':Val AUROC:' + str(results[model_name+' AUROC']))\n",
    "        results_risk[i][model_name +'Val AUROC'] = results[model_name+' AUROC']\n",
    "\n",
    "        # evaluate on test all\n",
    "        predictions = model.predict(X_test)\n",
    "        results, _ = print_metrics_binary_classification(y_test, predictions, model_name, verbose=1, logger=logger, wandb=wandb)\n",
    "        logger.info(model_name +':Test AUROC:' + str(results[model_name+' AUROC']))\n",
    "        results_risk[i][model_name +' Test AUROC'] = results[model_name+' AUROC']\n",
    "\n",
    "        # evaluate on included\n",
    "        predictions = model.predict(X_test[s_test==0])\n",
    "        results, _ = print_metrics_binary_classification(y_test[s_test==0], predictions, model_name, verbose=1, logger=logger, wandb=wandb)\n",
    "        logger.info(model_name +':Test AUROC(incl):' + str(results[model_name+' AUROC']))\n",
    "        results_risk[i][model_name +' Test AUROC(incl)'] = results[model_name+' AUROC']\n",
    "        # evaluate on excluded\n",
    "        if (y_test[s_test==1].sum() == y_test[s_test==1].shape[0]) or (y_test[s_test==1].sum() == 0):\n",
    "            # if there is only one class then AUROC is undefined so adding one sample from other class\n",
    "            if (y_test[s_test==1].sum() == 0):\n",
    "                predictions = model.predict(np.vstack((X_test[s_test==1], X_test[s_test==0][y_test[s_test==0]==1][:1,:].squeeze())))\n",
    "                results, _ = print_metrics_binary_classification(np.append(y_test[s_test==1], 1), predictions, model_name, verbose=1, logger=logger, wandb=wandb)\n",
    "                logger.info(model_name +':Test AUROC(excl):' + str(results[model_name+' AUROC']))\n",
    "                results_risk[i][model_name +' Test AUROC(excl)'] = results[model_name+' AUROC']\n",
    "            else:\n",
    "                predictions = model.predict(np.vstack((X_test[s_test==1], X_test[s_test==0][y_test[s_test==0]==0][:1,:].squeeze())))\n",
    "                results, _ = print_metrics_binary_classification(np.append(y_test[s_test==1], 0), predictions, model_name, verbose=1, logger=logger, wandb=wandb)\n",
    "                logger.info(model_name +':Test AUROC(excl):' + str(results[model_name+' AUROC']))\n",
    "                results_risk[i][model_name +' Test AUROC(excl)'] = results[model_name+' AUROC']\n",
    "        else:\n",
    "            predictions = model.predict(X_test[s_test==1])\n",
    "            results, _ = print_metrics_binary_classification(y_test[s_test==1], predictions, model_name, verbose=1, logger=logger, wandb=wandb)\n",
    "            logger.info(model_name +':Test AUROC(excl):' + str(results[model_name+' AUROC']))\n",
    "            results_risk[i][model_name +' Test AUROC(excl)'] = results[model_name+' AUROC']\n",
    "\n",
    "        ############################\n",
    "\n",
    "    return results_risk\n",
    "\n",
    "def study_effect(data_name, da_method, file_name, results_file, r, c, n, search_param=False):\n",
    "    ''' \n",
    "    This function is used to study effect of (riks rate, dataset size etc.).\n",
    "    It expects a set of datasets with some variations.\n",
    "    '''\n",
    "    logger.info('\\n\\n-------------N:'+str(n)+'--Risk Rate:' + str(r)+'--Censoring Rate:' + str(c)+'-------------------------.')\n",
    "\n",
    "    results_sizes = {}\n",
    "    for ni in n:\n",
    "        for ci in c:\n",
    "            for ri in r:\n",
    "                # load data dictionary\n",
    "                data_dict = get_data_dict(file_name, [ri], [ci], [ni])\n",
    "\n",
    "                logger.info('-----Running for Size:'+str(ni)+'--Risk Rate:' + str(ri)+'--Censoring Rate:' + str(ci)+'\\n-----------')\n",
    "                [X_train, y_train, s_train, X_val, y_val, s_val, X_test, y_test, s_test] = data_dict[str(ni)+'R'+str(ri)+'C'+str(ci)]\n",
    "                \n",
    "                data = [X_train, y_train, s_train, X_val, y_val, s_val, X_test, y_test, s_test]\n",
    "                \n",
    "                #############################\n",
    "                # Reading hyperparameters from the JSON file\n",
    "                with open('best_hyperparams.json', 'r') as json_file:\n",
    "                    best_hyperparams = json.load(json_file)\n",
    "                if (da_method+data_name+str(ni)+'R'+str(ri)+'C'+str(ci) not in best_hyperparams) or search_param:\n",
    "                    # hyperparameter tuning \n",
    "                    logger.info('Finding best hyperparams.')\n",
    "                    params, best_score, results = grid_search_kmm_kliep(da_method, X_train[s_train==0], y_train[s_train==0], X_val[s_val==0], y_val[s_val==0], X_test, ckpt_path, param_grid, EPOCHS, logger, wandb, device)\n",
    "                    logger.info('Hyperparam tuning:')\n",
    "                    logger.info(results)\n",
    "\n",
    "                    best_hyperparams[da_method+data_name+str(ni)+'R'+str(ri)+'C'+str(ci)] = {'params': params}\n",
    "                    # save best params\n",
    "                    with open('best_hyperparams.json', 'w') as json_file:\n",
    "                        json.dump(best_hyperparams, json_file)\n",
    "                else:\n",
    "                    logger.info('Accessing the existing best hyperparams.')\n",
    "                    params = best_hyperparams[da_method+data_name+str(ni)+'R'+str(ri)+'C'+str(ci)]['params']\n",
    "\n",
    "                ################################\n",
    "                # run experiments and repeat for given number of times\n",
    "                results = experiment(da_method, data, params, repeat=REPEAT)\n",
    "                logger.info('\\n\\nBest params for risk:\\n' + str(params))\n",
    "                logger.info(results)\n",
    "                results_sizes[str(ni)+'R'+str(ri)+'C'+str(ci)] = results\n",
    "\n",
    "                # save results\n",
    "                dict_to_file(results_file, results_sizes)\n",
    "                ################################\n",
    "\n",
    "    logger.info('\\n\\n------------------- Experiments ended-------------------.\\n'+str(results_sizes)+'\\n------------------------------------------------\\n\\n')\n",
    "\n",
    "    return results_sizes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T10:28:16.127183Z",
     "iopub.status.busy": "2024-03-10T10:28:16.126781Z",
     "iopub.status.idle": "2024-03-10T10:28:16.129900Z",
     "shell.execute_reply": "2024-03-10T10:28:16.129158Z"
    }
   },
   "outputs": [],
   "source": [
    "results_sizes = study_effect('synthetic', 'KMM', 'selection_bias_data.pkl', 'results_KMM', [.05, .1, .2, .3, .4], c=[.05, .1, .2, .3, .4], n=[1000, 2000, 3000, 4000, 5000], search_param=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T10:28:16.143685Z",
     "iopub.status.busy": "2024-03-10T10:28:16.143414Z",
     "iopub.status.idle": "2024-03-11T00:47:23.253325Z",
     "shell.execute_reply": "2024-03-11T00:47:23.252748Z"
    }
   },
   "outputs": [],
   "source": [
    "results_sizes = study_effect('synthetic', 'KLIEP', 'selection_bias_data.pkl', 'results_KLIEP-T', [.05, .1, .2, .3, .4], c=[.05, .1, .2, .3, .4], n=[1000, 2000, 3000, 4000, 5000], search_param=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T00:47:23.269453Z",
     "iopub.status.busy": "2024-03-11T00:47:23.268810Z",
     "iopub.status.idle": "2024-03-11T00:47:23.272536Z",
     "shell.execute_reply": "2024-03-11T00:47:23.271669Z"
    }
   },
   "outputs": [],
   "source": [
    "results_sizes = study_effect('diabetes', 'KMM', 'diabetes_bias_data.pkl', 'results_KMM-diabetes', r=[.05, .1, .2, .3, .4], c=[.05, .1, .2, .3, .4], n=[25000, 10000, 5000, 2000, 1000], search_param=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T00:47:23.287448Z",
     "iopub.status.busy": "2024-03-11T00:47:23.287058Z",
     "iopub.status.idle": "2024-03-11T12:09:56.291430Z",
     "shell.execute_reply": "2024-03-11T12:09:56.290361Z"
    }
   },
   "outputs": [],
   "source": [
    "results_sizes = study_effect('diabetes', 'KLIEP', 'diabetes_bias_data.pkl', 'results_KLIEP-diabetes-T', r=[.05, .1, .2, .3, .4], c=[.05, .1, .2, .3, .4], n=[25000, 10000, 5000, 2000, 1000], search_param=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T12:09:56.319953Z",
     "iopub.status.busy": "2024-03-11T12:09:56.319743Z",
     "iopub.status.idle": "2024-03-11T12:09:56.323110Z",
     "shell.execute_reply": "2024-03-11T12:09:56.322446Z"
    }
   },
   "outputs": [],
   "source": [
    "results_sizes = study_effect('covid', 'KMM', 'covid_bias_data.pkl', 'results_KMM-covid', r=[.05, .1, .2, .3, .4], c=[.05, .1, .2, .3, .4], n=[15000, 10000, 5000, 2000, 1000], search_param=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T12:09:56.325646Z",
     "iopub.status.busy": "2024-03-11T12:09:56.325310Z",
     "iopub.status.idle": "2024-03-11T22:00:17.444042Z",
     "shell.execute_reply": "2024-03-11T22:00:17.443497Z"
    }
   },
   "outputs": [],
   "source": [
    "results_sizes = study_effect('covid', 'KLIEP', 'covid_bias_data.pkl', 'results_KLIEP-covid-T', r=[.05, .1, .2, .3, .4], c=[.05, .1, .2, .3, .4], n=[15000, 10000, 5000, 2000, 1000], search_param=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
