{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve Selection Bias by Multitasking\n",
    "\n",
    "- Train multitasking model on biased data to predict risk as well as sensoring\n",
    "- Use sensoring prediction task to identify units and use risk prediction for identified units only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T21:32:36.327406Z",
     "iopub.status.busy": "2024-02-09T21:32:36.327138Z",
     "iopub.status.idle": "2024-02-09T21:32:39.816384Z",
     "shell.execute_reply": "2024-02-09T21:32:39.815424Z"
    }
   },
   "outputs": [],
   "source": [
    "# set working directory\n",
    "from random import SystemRandom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "# from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "  \n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# from torch._C import float32\n",
    "import argparse\n",
    "from asyncio.log import logger\n",
    "import os, math\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Importing matplotlib and seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "# import tabulate\n",
    "\n",
    "# import utils\n",
    "from utils import *\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T21:32:39.821941Z",
     "iopub.status.busy": "2024-02-09T21:32:39.820953Z",
     "iopub.status.idle": "2024-02-09T21:32:39.898680Z",
     "shell.execute_reply": "2024-02-09T21:32:39.897956Z"
    }
   },
   "outputs": [],
   "source": [
    "MINI_BATCH = 64\n",
    "MINI_BATCH2 = 256\n",
    "EPOCHS = 1000\n",
    "LOAD = None\n",
    "SEED = 42\n",
    "REPEAT = 10\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Set device to GPU\n",
    "    print(\"CUDA is available! Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Set device to CPU\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "param_grid = {\n",
    "            'drop_rate': [0.1],\n",
    "            'hidden_sizes':[[50], [100], [100, 100]],# [[50], [50, 50], [50, 100], [100], [100, 100]],\n",
    "            'head_sizes':[[50], [100]],# [[50], [100]],\n",
    "            'lr':[0.0001, 0.0005]\n",
    "        }\n",
    "# params_risk = {\n",
    "#             'drop_rate': 0.05,\n",
    "#             'hidden_sizes':[50],# [[50], [50, 50], [50, 100], [100], [100, 100]],\n",
    "#             'head_sizes':[32],# [[50], [100]],\n",
    "#             'lr':0.0001\n",
    "#         }\n",
    "# best_param = params_risk \n",
    "############################################\n",
    "# initilising wandb\n",
    "# wandb.init(project='SeletionBML', entity=\"jmdvinodjmd\")\n",
    "wandb.init(mode=\"disabled\")\n",
    "wandb.run.name = 'SB'\n",
    "makedirs('./results/')\n",
    "experimentID = LOAD\n",
    "if experimentID is None:\n",
    "    experimentID = int(SystemRandom().random()*100000)\n",
    "# checkpoint\n",
    "ckpt_path = os.path.join('./results/checkpoints/MT_model.ckpt')\n",
    "makedirs('./results/checkpoints/')\n",
    "# set logger\n",
    "log_path = os.path.join(\"./results/logs/\" + \"exp_MT_\" + str(experimentID) + \".log\")\n",
    "makedirs(\"./results/logs/\")\n",
    "logger = get_logger(logpath=log_path, filepath=\"exp_MT_\" + str(experimentID) + \".log\", displaying=False)\n",
    "logger.info(\"Experiment \" + str(experimentID))\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T21:32:39.910529Z",
     "iopub.status.busy": "2024-02-09T21:32:39.910179Z",
     "iopub.status.idle": "2024-02-09T21:32:39.935183Z",
     "shell.execute_reply": "2024-02-09T21:32:39.933931Z"
    }
   },
   "outputs": [],
   "source": [
    "def experiment(data, params, repeat=1):\n",
    "    [X_train, y_train, s_train, X_val, y_val, s_val, X_test, y_test, s_test] = data\n",
    "\n",
    "    # loader preparation\n",
    "    loader_train, input_size = get_loaders([X_train, y_train, s_train], batch_size=MINI_BATCH, is_train=True, device=device)\n",
    "    loader_val, _ = get_loaders([X_val, y_val, s_val], batch_size=X_val.shape[0], is_train=False, device=device)\n",
    "    loader_test, _ = get_loaders([X_test, y_test, s_test], batch_size=X_test.shape[0], is_train=False, device=device)\n",
    "\n",
    "    # repeating experiment for a given number of times\n",
    "    results_risk = {}\n",
    "    for i in range(repeat):\n",
    "        logger.info('Repeating: ' + str(i+1))\n",
    "        results_risk[i] = {}\n",
    "        #############################\n",
    "        # train model\n",
    "        model_risk, optimizer, criterion = create_model('Multitasking', params, input_size, output_size=1, device=device)\n",
    "        early_stopping = EarlyStopping(patience=10, path=ckpt_path, verbose=True, logger=logger)\n",
    "        logger.info(model_risk)\n",
    "        wandb.watch(model_risk)\n",
    "        # train\n",
    "        model_risk = train_model(model_risk, 'Multitasking', loader_train, loader_val, optimizer, criterion, early_stopping, logger, epochs=EPOCHS, plot=False, wandb=wandb)\n",
    "        # evaluate\n",
    "        auroc_vb, best_threshold, _ = evaluate_model('Val', loader_val, model_risk, 'Multitasking', criterion, logger, -1, device, wandb)\n",
    "        auroc_tb, _, _ = evaluate_model('Val', loader_test, model_risk, 'Multitasking', criterion, logger, -1, device, wandb)\n",
    "        auroc_tu, _, _ = evaluate_model('Test', loader_test, model_risk, 'Multitasking', criterion, logger, -1, device, wandb)\n",
    "        \n",
    "        logger.info('Biased VAL AUROC:' + str(auroc_vb['Val AUROC']) + ' biased Test AUROC:' + str(auroc_tb['Val AUROC']) + ' unbiased Test AUROC:' + str(auroc_tu['Test AUROC']))\n",
    "        results_risk[i] = {'VAL AUROC-B':auroc_vb['Val AUROC'], 'Test AUROC-B':auroc_tb['Val AUROC'], 'Test AUROC-U':auroc_tu['Test AUROC'], 'C-Test AUROC-U':auroc_tu['C-Test AUROC']}\n",
    "\n",
    "        ############################\n",
    "        # Identify sensored and predict risk for unsensored\n",
    "        logger.info('Best threshold:'+ str(best_threshold))\n",
    "        _, preds_sensoring, _ = model_risk(torch.tensor(X_test, dtype=torch.float).to(device))\n",
    "        sensored_units = (preds_sensoring > torch.tensor(best_threshold, dtype=torch.float).to(device)).cpu().numpy().astype(int)\n",
    "        loader_utest, _ = get_loaders([X_test[sensored_units.squeeze()==0], y_test[sensored_units.squeeze()==0], s_test[sensored_units.squeeze()==0]], batch_size=y_test.shape[0], is_train=False, device=device)\n",
    "        \n",
    "        # check if all censored or none\n",
    "        if (sensored_units.sum()==0) or (sensored_units.sum()==X_test.shape[0]) or (y_test[sensored_units.squeeze()==0].sum()==0) or (y_test[sensored_units.squeeze()==0].sum()==y_test[sensored_units.squeeze()==0].shape[0]):\n",
    "            auroc = {'TB-EU:Multitasking AUROC':-1}\n",
    "            continue\n",
    "        else:\n",
    "            logger.info('sizes:'+str(X_test[sensored_units.squeeze()==0].shape)+str(X_test.shape)+'---------------')\n",
    "            logger.info('sizes:'+str(y_test[sensored_units.squeeze()==0].shape)+str(y_test[sensored_units.squeeze()==0].sum())+'---------------')\n",
    "            auroc, _, _ = evaluate_model('TB-EU:Multitasking', loader_utest, model_risk, 'Multitasking', criterion, logger, -1, device, wandb)\n",
    "\n",
    "        logger.info('Multitasking Test AUROC-U:' + str(auroc['TB-EU:Multitasking AUROC']) + '. Unensored/Total:' + str(X_test[sensored_units.squeeze()==0].shape[0])+ '/'+str(X_test.shape[0])\\\n",
    "                    +'. Actual Unensored/Total:' + str(X_test[s_test.squeeze()==0].shape[0])+ '/'+str(X_test.shape[0]))\n",
    "        results_risk[i].update({'Test AUROC-Multitasking':auroc['TB-EU:Multitasking AUROC'], 'Predicted Sensored':sensored_units.sum(), 'Actual Sensored':s_test.sum()})\n",
    "    \n",
    "    return results_risk\n",
    "\n",
    "def study_effect(data_name, file_name, results_file, r, c, n, search_param=False):\n",
    "    ''' \n",
    "    This function is used to study effect of (riks rate, dataset size etc.).\n",
    "    It expects a set of datasets with some variations.\n",
    "    '''\n",
    "    logger.info('\\n\\n-------------N:'+str(n)+'--Risk Rate:' + str(r)+'--Censoring Rate:' + str(c)+'-------------------------.')\n",
    "\n",
    "    results_sizes = {}\n",
    "    for ni in n:\n",
    "        for ci in c:\n",
    "            for ri in r:\n",
    "                # load data dictionary\n",
    "                data_dict = get_data_dict(file_name, [ri], [ci], [ni])\n",
    "\n",
    "                logger.info('-----Running for Size:'+str(ni)+'--Risk Rate:' + str(ri)+'--Censoring Rate:' + str(ci)+'\\n-----------')\n",
    "                [X_train, y_train, s_train, X_val, y_val, s_val, X_test, y_test, s_test] = data_dict[str(ni)+'R'+str(ri)+'C'+str(ci)]\n",
    "                data = [X_train, y_train, s_train, X_val, y_val, s_val, X_test, y_test, s_test]\n",
    "        \n",
    "                ##############################\n",
    "                # Reading hyperparameters from the JSON file\n",
    "                with open('best_hyperparams.json', 'r') as json_file:\n",
    "                    best_hyperparams = json.load(json_file)\n",
    "                if ('Multitasking-'+data_name+str(ni)+'R'+str(ri)+'C'+str(ci) not in best_hyperparams) or search_param:\n",
    "                    # hyperparameter tuning  \n",
    "                    logger.info('Finding best hyperparams.') \n",
    "                    loader_train_br, input_size = get_loaders([X_train, y_train, s_train], batch_size=MINI_BATCH, is_train=True, device=device)\n",
    "                    loader_val_br, _ = get_loaders([X_val, y_val, s_val], batch_size=y_val.shape[0], is_train=False, device=device)\n",
    "                    best_param, best_score, results = grid_search_MLP('Multitasking', loader_train_br, loader_val_br, input_size, ckpt_path, param_grid, EPOCHS, logger, wandb, device)\n",
    "                    logger.info('Hyperparam tuning for Multitasking network:')\n",
    "                    logger.info(results)\n",
    "\n",
    "                    best_hyperparams['Multitasking-'+data_name+str(ni)+'R'+str(ri)+'C'+str(ci)] = {'best_param': best_param}\n",
    "                    # save best params\n",
    "                    with open('best_hyperparams.json', 'w') as json_file:\n",
    "                        json.dump(best_hyperparams, json_file)\n",
    "                \n",
    "                else:\n",
    "                    logger.info('Accessing the existing best hyperparams.')\n",
    "                    best_param = best_hyperparams['Multitasking-'+data_name+str(ni)+'R'+str(ri)+'C'+str(ci)]['best_param']\n",
    "\n",
    "                ################################\n",
    "                # run experiments and repeat for given number of times\n",
    "                results = experiment(data, best_param, repeat=REPEAT)\n",
    "                logger.info('\\n\\nBest params for Multitasking network:\\n' + str(best_param))\n",
    "                logger.info(results)\n",
    "                results_sizes[str(ni)+'R'+str(ri)+'C'+str(ci)] = results\n",
    "\n",
    "                # save results\n",
    "                dict_to_file(results_file, results_sizes)\n",
    "                ################################\n",
    "\n",
    "    logger.info('\\n\\n------------------- Experiments ended-------------------.\\n'+str(results_sizes)+'\\n------------------------------------------------\\n\\n')\n",
    "\n",
    "    return results_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T21:32:39.951907Z",
     "iopub.status.busy": "2024-02-09T21:32:39.951392Z",
     "iopub.status.idle": "2024-02-09T21:32:39.954652Z",
     "shell.execute_reply": "2024-02-09T21:32:39.953884Z"
    }
   },
   "outputs": [],
   "source": [
    "results_sizes = study_effect('synthetic', 'selection_bias_data.pkl', 'results_MTNet', r=[.05, .1, .2, .3, .4], c=[.05, .1, .2, .3, .4], n=[1000, 2000, 3000, 4000, 5000], search_param=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T21:32:39.976160Z",
     "iopub.status.busy": "2024-02-09T21:32:39.975911Z",
     "iopub.status.idle": "2024-02-10T18:49:12.971745Z",
     "shell.execute_reply": "2024-02-10T18:49:12.971164Z"
    }
   },
   "outputs": [],
   "source": [
    "results_sizes = study_effect('diabetes', 'diabetes_bias_data.pkl', 'results_MTNet-diabetes', r=[.05, .1, .2, .3, .4], c=[.05, .1, .2, .3, .4], n=[25000, 10000, 5000, 2000, 1000], search_param=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T18:49:12.986903Z",
     "iopub.status.busy": "2024-02-10T18:49:12.986672Z",
     "iopub.status.idle": "2024-02-10T18:49:12.989866Z",
     "shell.execute_reply": "2024-02-10T18:49:12.989068Z"
    }
   },
   "outputs": [],
   "source": [
    "results_sizes = study_effect('covid', 'covid_bias_data.pkl', 'results_MTNet-covid', r=[.05, .1, .2, .3, .4], c=[.3, .4], n=[15000, 10000, 5000, 2000, 1000], search_param=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
